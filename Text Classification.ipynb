{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Klasifikasi Teks Erotis (Pornoteks) Bahasa Indonesia"
      ],
      "metadata": {
        "id": "hwFb-smuOa7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pF7JhPWoSRrg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout, Conv1D\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"dataset500.csv\")\n",
        "\n",
        "X = dataset[\"text\"]\n",
        "y = dataset[\"label\"]"
      ],
      "metadata": {
        "id": "5ke-ECRATWKI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text_train, Text_temp, Label_train, Label_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "Text_val, Text_test, Label_val, Label_test = train_test_split(Text_temp, Label_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "6ltOmuPpUHkb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on your labels and transform them\n",
        "Label_train = label_encoder.fit_transform(Label_train)\n",
        "Label_val = label_encoder.transform(Label_val)\n",
        "Label_test = label_encoder.transform(Label_test)\n",
        "\n",
        "# 0: NEGATIF\n",
        "# 1: POSITIF"
      ],
      "metadata": {
        "id": "Dnr63S0tsAIz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((Text_train, Label_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((Text_val, Label_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((Text_test, Label_test))"
      ],
      "metadata": {
        "id": "O1WA4reAU5s1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ],
      "metadata": {
        "id": "j2Q3zUI6VuPd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjLxy9S8VmO-",
        "outputId": "290e51ee-6dfe-4c07-e8b9-7b09b5d59c3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.34560610e-02, -4.64357510e-02, -1.48817785e-02,\n",
              "         4.64683771e-03, -7.69165903e-03],\n",
              "       [-6.45349175e-03,  1.01177469e-02, -5.72475046e-03,\n",
              "        -9.78541374e-03, -9.81241465e-06],\n",
              "       [ 4.89111580e-02,  4.52224277e-02,  1.60588138e-02,\n",
              "         4.64906357e-02, -5.66937774e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding_layer(tf.constant([[0, 1, 2], [3, 4, 5]]))\n",
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fteKRAWCVm0b",
        "outputId": "427375aa-40d0-436c-bd1d-d760ddb35730"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the train_dataset, val_dataset, test_dataset specifications\n",
        "batch_size = 32  # You can set the batch size to your desired value\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "ngMHXXNAIp92"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ZqZN7kxHN-3t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_dataset.take(1):\n",
        "  for i in range(10):\n",
        "    print(\"Text: \", text_batch.numpy()[i])\n",
        "    print(\"Label:\", label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeOaEa8RJPTK",
        "outputId": "a303fd5e-919d-44ea-e9ed-dd31d095bec4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  b'mas kocok mas eghh mas yang dalam kocok terus selangkanganku aduhh eghh mas enakk'\n",
            "Label: 0\n",
            "Text:  b'sementara tangan kananku mulai menggerayangi memek  yang sudah mulai basahaku usap-usap bibir memek tante dengan lembut hingga desahan-desahan menggairahkan semakin keras dari bibirnya'\n",
            "Label: 0\n",
            "Text:  b'pemodelan topik merupakan metode untuk menemukan tema utama yang mencakup koleksi dokumen besar dan tidak terstruktur yang dapat menyusun dataset sesuai dengan tema yang ditemukan di dalamnya'\n",
            "Label: 1\n",
            "Text:  b'tahap ini dilakukan dengan mencari, menggali dan mempelajari informasi yang berhubungan dengan skripsi ini. informasi didapat melalui buku-buku referensi atau sumber-sumber yang berkaitan dengan skripsi ini, baik dari text book maupun internet'\n",
            "Label: 1\n",
            "Text:  b'Banyak juga wanita yang lebih menyukai rangsangan seksual pada klitoris secara langsung atau manual'\n",
            "Label: 1\n",
            "Text:  b'Makanan yang mengandung CoQ10 dan likopen juga dapat membantu meningkatkan libido'\n",
            "Label: 1\n",
            "Text:  b'Penanganan anafilaksis yang terlambat bisa menyebabkan kematian akibat penyempitan saluran udara'\n",
            "Label: 1\n",
            "Text:  b'pas saat itu, kepalaku dipegang lia, dibawanya ke payudara sebelah kiri'\n",
            "Label: 0\n",
            "Text:  b'oh, rupanya sewaktu dia mandi sudah dibersihkan dan disabun dengan baik sehingga bau vaginanya harum'\n",
            "Label: 0\n",
            "Text:  b'kehadiran internet sebagai media informasi memberikan dampak positif bagi kehidupan masyarakat, baik dibidang teknologi, ekonomi, sosial, hiburan dan dibidang lainnya tidak hanya dampak positif, internet juga memberikan dampak negatif, salah satunya adalah mudahnya masyarakat dalam mengakses berbagai konten negatif'\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, label in enumerate(label_encoder.classes_):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQusoFp0JsTN",
        "outputId": "fc809d31-f3a6-4249-9bb7-c55f7be87e41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to negatif\n",
            "Label 1 corresponds to positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 16\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length,\n",
        ")"
      ],
      "metadata": {
        "id": "P0wsbjyeWSM1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = train_dataset.map(lambda text, labels: text)\n",
        "vectorize_layer.adapt(train_text)\n",
        "print(len(vectorize_layer.get_vocabulary()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpdUS8FQn2DI",
        "outputId": "8ce34f3f-4f06-4aee-b37c-b4b49f4200eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) from the dataset.\n",
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "first_text, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Text:\", first_text)\n",
        "print(\"Label:\", first_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCIt6E_fPDkI",
        "outputId": "da3b102d-6930-43cb-a899-947bebd175f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: tf.Tensor(b'mas kocok mas eghh mas yang dalam kocok terus selangkanganku aduhh eghh mas enakk', shape=(), dtype=string)\n",
            "Label: tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"'int' vectorized text:\",\n",
        "      vectorize_layer(first_text).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3buiCRbtPaGJ",
        "outputId": "b9832555-f386-4be0-e5cc-fb28e23fadad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'int' vectorized text: [ 134  821  134  504  134    3   18  821   35 1012 1463  504  134 3026\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"2000 ---> \", vectorize_layer.get_vocabulary()[2000])\n",
        "print(\"205 ---> \", vectorize_layer.get_vocabulary()[205])\n",
        "print(\"Vocabulary size: {}\".format(len(vectorize_layer.get_vocabulary())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfb87KCwPiKe",
        "outputId": "5a88bfde-2a20-4682-9fd0-79cbf2e9176c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000 --->  pergumulan\n",
            "205 --->  menjilati\n",
            "Vocabulary size: 3590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dropout(0.1),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dropout(0.1),\n",
        "  Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "wsMfkJfiZbd4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # Use binary cross-entropy for binary classification\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zy8GprNKicFW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset,  # Shuffle and batch the training data\n",
        "    validation_data=val_dataset,  # Batch the validation data\n",
        "    epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKjkBWBSij8V",
        "outputId": "f4e468ef-b13a-47a9-f7fc-60379850d934"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "19/19 [==============================] - 3s 37ms/step - loss: 0.6934 - accuracy: 0.5133 - val_loss: 0.6915 - val_accuracy: 0.6750\n",
            "Epoch 2/15\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.6905 - accuracy: 0.6567 - val_loss: 0.6884 - val_accuracy: 0.8100\n",
            "Epoch 3/15\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.6863 - accuracy: 0.7533 - val_loss: 0.6844 - val_accuracy: 0.9350\n",
            "Epoch 4/15\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.6804 - accuracy: 0.8017 - val_loss: 0.6787 - val_accuracy: 0.9000\n",
            "Epoch 5/15\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.6724 - accuracy: 0.8667 - val_loss: 0.6704 - val_accuracy: 0.9250\n",
            "Epoch 6/15\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.6613 - accuracy: 0.8683 - val_loss: 0.6595 - val_accuracy: 0.9550\n",
            "Epoch 7/15\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.6468 - accuracy: 0.9133 - val_loss: 0.6454 - val_accuracy: 0.9650\n",
            "Epoch 8/15\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.6288 - accuracy: 0.9017 - val_loss: 0.6280 - val_accuracy: 0.9600\n",
            "Epoch 9/15\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.6050 - accuracy: 0.9217 - val_loss: 0.6077 - val_accuracy: 0.9450\n",
            "Epoch 10/15\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.5782 - accuracy: 0.9383 - val_loss: 0.5841 - val_accuracy: 0.9650\n",
            "Epoch 11/15\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.5499 - accuracy: 0.9483 - val_loss: 0.5582 - val_accuracy: 0.9850\n",
            "Epoch 12/15\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.5205 - accuracy: 0.9617 - val_loss: 0.5311 - val_accuracy: 0.9850\n",
            "Epoch 13/15\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.4918 - accuracy: 0.9583 - val_loss: 0.5032 - val_accuracy: 0.9850\n",
            "Epoch 14/15\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.4530 - accuracy: 0.9767 - val_loss: 0.4740 - val_accuracy: 0.9850\n",
            "Epoch 15/15\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.4208 - accuracy: 0.9817 - val_loss: 0.4435 - val_accuracy: 0.9700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7984cd5e6350>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaAQpABiGNs1",
        "outputId": "3c5b2de6-7df6-49ed-cb1e-c9d5f212bed4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVe  (None, 100)               0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 16)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160289 (626.13 KB)\n",
            "Trainable params: 160289 (626.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_model\", save_format='tf')"
      ],
      "metadata": {
        "id": "YpDkss912Ex1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r saved_model.zip my_model\n",
        "files.download(\"saved_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "x3ckWM_VNNrF",
        "outputId": "73d13c13-8f73-43b0-9775-2e4a2a2b0e8d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: my_model/ (stored 0%)\n",
            "  adding: my_model/keras_metadata.pb (deflated 87%)\n",
            "  adding: my_model/assets/ (stored 0%)\n",
            "  adding: my_model/saved_model.pb (deflated 80%)\n",
            "  adding: my_model/variables/ (stored 0%)\n",
            "  adding: my_model/variables/variables.data-00000-of-00001 (deflated 55%)\n",
            "  adding: my_model/variables/variables.index (deflated 56%)\n",
            "  adding: my_model/fingerprint.pb (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_761f69b3-2437-45e5-89be-e002008b2f05\", \"saved_model.zip\", 917540)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load('my_model')"
      ],
      "metadata": {
        "id": "VQ87Ra5k4tzs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "for text_batch, label_batch in test_dataset:\n",
        "  for i in range(len(label_batch)):\n",
        "    true_labels.append(label_batch.numpy()[i])\n",
        "\n",
        "print(len(true_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQvilXaXBs2r",
        "outputId": "990b6545-b819-4bb5-f95a-0c2d18bd47b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    \"ngentot yuk\",\n",
        "    \"Uhh kegedean tuh\",\n",
        "    \"rasanya pen bet dah gua sedot tuh gunung\",\n",
        "    \"Kaka Buka Dong Bajunya\",\n",
        "    \"Love yang mau remas t3t3knya\",\n",
        "    \"Seru nih kenyot nenen nya\",\n",
        "    \"ngentot yu\",\n",
        "    \"toket\",\n",
        "    \"Kumpulan cerita sex terbaru, cersex bergambar, kisah hot, cerita dewasa, cerita mesum, cerpen ngentot, cerita selingkuh dan cerita seks pemerkosaan\",\n",
        "    \"bacapres 2024 adu debat di TVONE\",\n",
        "    \"aku remas t3t3knya\",\n",
        "    \"owhh hhahh nghhahh goyang yang keras! hhahh ennnakkkhh mmhh enakkkhterus katryn bilang, mau spank nggak? katanya\",\n",
        "    \"saya jambak rambutnya yang panjang dan saya tarik sampai bisa saya remas payudaranya yang besar\",\n",
        "    \"enak banget hari ini aku bercinta sama pacarku\",\n",
        "    \"gigitannya yang kecil-kecil ini yang membuat saya meringis kenikmatan campur kesakitan yang bikin saya takluk sama dia\"\n",
        "]\n",
        "\n",
        "predictions = model.predict(test_dataset)\n",
        "\n",
        "# Define a threshold for classification (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "\n",
        "# Use a conditional statement to get the predicted labels as strings\n",
        "predicted_labels = [1 if p >= threshold else 0 for p in predictions]\n",
        "print(len(predicted_labels))\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(accuracy)\n",
        "# Print the predicted labels\n",
        "# for example, label in zip(Text_test, predicted_labels):\n",
        "    # print(f\"Input Text: {Text_test}\")\n",
        "    # print(f\"Predicted Label: {label}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTxLBlOk5D3H",
        "outputId": "522256e2-0ab8-40aa-9a9a-7a73d710be0f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n",
            "200\n",
            "0.97\n"
          ]
        }
      ]
    }
  ]
}